<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Audio Reactive Spheres</title>
    <style>
        body { margin: 0; overflow: hidden; }
    </style>
    <script src="https://threejs.org/build/three.js"></script>
</head>
<body>
    <button id="startButton">Start</button>

    <div id="container"></div>
    <script>
        // Create the scene, camera, renderer, etc...
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);
        camera.position.z = 2;  // Adjust camera position
        const renderer = new THREE.WebGLRenderer();

        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);
        
        // You'll need to set up the audio analyser here...
        // Replace this with your actual analyser initialization.
        var analyser;

        let numBands = 128;  // The initial number of bands.
        let volumeThreshold = 20;
        
        // Points and lines
        let points = [];
        let lines = [];

        // Generate points on the surface of a sphere using the Golden Spiral algorithm
        let goldenRatio = (1 + Math.sqrt(5)) / 2;
        let angleIncrement = Math.PI * 2 * goldenRatio;

        for (let i = 0; i < numBands; i++) {
            let y = 1 - (i / numBands) + (1 / (2 * numBands));  // y goes from 1 to 0
            let radius = Math.sqrt(1 - y*y);  // radius at y

            let theta = angleIncrement * i;

            let x = Math.cos(theta) * radius;
            let z = Math.sin(theta) * radius;

            // Ensure that x, y, z are not NaN
            x = isNaN(x) ? 0 : x;
            y = isNaN(y) ? 0 : y;
            z = isNaN(z) ? 0 : z;


            let point = new THREE.Points(new THREE.BufferGeometry().setFromPoints([new THREE.Vector3(0, 0, 0)]), new THREE.PointsMaterial({color: 0xffffff}));
            point.position.set(x, y, z);
            scene.add(point);
            points.push(point);
        }

        function getAverageVolume(array) {
            var values = 0;
            var average;
            var length = array.length;
            for (var i = 0; i < length; i++) {
                values += array[i];
            }
            average = values / length;
            return average;
        }

        function animate() {
            requestAnimationFrame(animate);

            // Analyze the audio data
            let data = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(data);

            let bandSize = Math.floor(data.length / numBands);

            for (let i = 0; i < numBands; i++) {
                let band = data.slice(i * bandSize, (i + 1) * bandSize);
                let volume = getAverageVolume(band);
                
                if (volume > volumeThreshold) {
                    let color = new THREE.Color('hsl(' + volume + ', 100%, 50%)');
                    points[i].material.color = color;  // Change point color

                    // Draw lines to other points that are also above the threshold
                    for (let j = 0; j < i; j++) {
                        let otherBand = data.slice(j * bandSize, (j + 1) * bandSize);
                        let otherVolume = getAverageVolume(otherBand);

                        if (otherVolume > volumeThreshold) {
                            let geometry = new THREE.BufferGeometry().setFromPoints([points[i].position, points[j].position]);
                            let line = new THREE.Line(geometry, new THREE.LineBasicMaterial({color: color}));
                            scene.add(line);
                            lines.push(line);
                        }
                    }
                }
            }

            // Render the scene
            renderer.render(scene, camera);
        }

        document.getElementById('startButton').addEventListener('click', function() {
            setupAudio();
            animate();
        });

        function setupAudio() {
            // Set up the audio context and analyser.
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();

            // Connect the microphone stream to the analyzer and the analyzer to the destination.
            navigator.mediaDevices.getUserMedia({ audio: true, video: false })
                .then(function(stream) {
                    // Create a gain node to prevent audio feedback.
                    let gainNode = audioContext.createGain();
                    gainNode.gain.value = 0;  // Mute the audio.

                    let source = audioContext.createMediaStreamSource(stream);
                    source.connect(analyser);
                    analyser.connect(gainNode);
                    gainNode.connect(audioContext.destination);

                    // Start rendering the visualization.
                    animate();
                })
                .catch(function(err) {
                    console.log('The following error occured: ' + err);
                });
        }
    </script>
</body>
</html>
